{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Program to perform acoustic signal augmentation - generate new audio clips using existing ones."
      ],
      "metadata": {
        "id": "uFp-EehCtBDU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "G-sEwAIW1fA0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path, PurePath\n",
        "\n",
        "try:\n",
        "  import csv\n",
        "except:\n",
        "  !pip3 install csv\n",
        "\n",
        "import numpy\n",
        "\n",
        "try:\n",
        "  from pydub import AudioSegment\n",
        "  from pydub.utils import get_array_type\n",
        "except:\n",
        "  !pip3 install pydub\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, code cell contains variables with the relevant directory paths."
      ],
      "metadata": {
        "id": "L7VQDv1eq91y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Path for directory containing raw audio clips\n",
        "raw_audio_clips_path = '/content/drive/MyDrive/Data-science_learnt_applied/Problems/Juliana_bio-acoustic_FiebergLab_UoM/Datasets/Tapir/Raw-audio-files'\n",
        "\n",
        "# Path for directory containing spectrograms generated from raw audio clips\n",
        "raw_audio_spectrograms_path = '/content/drive/MyDrive/Data-science_learnt_applied/Problems/Juliana_bio-acoustic_FiebergLab_UoM/Datasets/Tapir/Spectrograms-for-raw-clips'\n",
        "\n",
        "# Path for directory containing synthetic audio clips with silence in b/g\n",
        "# generated from raw audio clips\n",
        "augmented_audio_with_silence_path = '/content/drive/MyDrive/Data-science_learnt_applied/Problems/Juliana_bio-acoustic_FiebergLab_UoM/Datasets/Tapir/Synthetic-clips_with-silence'\n",
        "\n",
        "# Path for directory containing synthetic audio clips with real b/g generated\n",
        "# from raw audio clips\n",
        "augmented_audio_with_background_path = '/content/drive/MyDrive/Data-science_learnt_applied/Problems/Juliana_bio-acoustic_FiebergLab_UoM/Datasets/Tapir/Synthetic-clips_with-background'\n",
        "\n",
        "# Path for the metadata - CSV file containing filenames for raw audio clips\n",
        "raw_clips_metadata_path = '/content/drive/MyDrive/Data-science_learnt_applied/Problems/Juliana_bio-acoustic_FiebergLab_UoM/Datasets/Tapir/metadata_raw-audio-files.csv'\n"
      ],
      "metadata": {
        "id": "8yZvJYi0qrMf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code cell generates new audio clips with silence at all times other than the duration of the tapir call."
      ],
      "metadata": {
        "id": "jrgJgBm1uDzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_wi_silence(path, stem, *time):\n",
        "# The method takes the path of the audio file, its stem (which is the name\n",
        "# excluding the extension), and start and end times of each tapir call in the\n",
        "# clp as arguments.\n",
        "\n",
        "  clips = numpy.zeros([5], dtype=object)\n",
        "  # To temporarily store synthetic clips generated. Using each tapir call, five\n",
        "  # 5s clips are generated.\n",
        "\n",
        "  for t in range(int(len(time)/2)):\n",
        "  # Loop runs as many times as the number of tapir calls\n",
        "    for i in range(0, 5000, 1000):\n",
        "      clips[int(i/1000)] = AudioSegment.silent(duration=i) + AudioSegment.\\\n",
        "      from_file(path)[time[2*t]:time[2*t+1]] + AudioSegment.silent\\\n",
        "      (duration=5000-i-time[2*t+1]+time[2*t])\n",
        "      # Creates five 5 sec clips w/ tapir call positioned at times 0s, 1s, 2s,\n",
        "      # 3s, 4s.\n",
        "\n",
        "    for i in range(len(clips)):\n",
        "      clips[i].export(Path(augmented_audio_with_silence_path, stem + '_' +\\\n",
        "                           str(t+1) + '_' + str(i+1)+ '.wav'), format='wav')\n",
        "      # Saves each clip using the name of the original file, the number of\n",
        "      # tapir call interval in the original file, and the position of the tapir\n",
        "      # call in the generated clip.\n",
        "\n",
        "with open(Path(raw_clips_metadata_path), 'r') as file_object:\n",
        "  file_reader = csv.reader(file_object, delimiter=',')\n",
        "  for raw_audio_meta in file_reader:\n",
        "    interval = [int(x) for x in raw_audio_meta[1:] if x]\n",
        "    augment_wi_silence(\n",
        "        Path(raw_audio_clips_path, raw_audio_meta[0]),\n",
        "        PurePath(Path(raw_audio_clips_path, raw_audio_meta[0])).stem,\n",
        "        *interval\n",
        "    )"
      ],
      "metadata": {
        "id": "ZdLDv5LkCfyV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The next code cell generates new audio clips with background taken from the original clips."
      ],
      "metadata": {
        "id": "-cmtXp47vGm2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def augment_wi_background(path, stem, *time):\n",
        "# The method takes the path of the audio file, its stem (which is the name\n",
        "# excluding the extension), and start and end times of each tapir call in the\n",
        "# clp as arguments.\n",
        "\n",
        "  clips = numpy.zeros([5], dtype=object)\n",
        "  \n",
        "  for t in range(int(len(time)/2)):\n",
        "    for i in range(int(time[0]/5000)*5000, int(time[0]/5000)*5000+5000, 1000):\n",
        "      if i<time[2*t] and i<time[2*t+1]:\n",
        "        clips[int(i/1000-5*int(i/5000))] = AudioSegment.from_file(path)\\\n",
        "        [5000*int(time[2*t]/5000):i] + AudioSegment.from_file(path)\\\n",
        "        [time[2*t]:time[2*t+1]] + AudioSegment.from_file(path)[i:time[2*t]] +\\\n",
        "        AudioSegment.from_file(path)[time[2*t+1]:5000*int(time[2*t]/5000)+5000]\n",
        "      elif i>time[2*t] and i<time[2*t+1]:\n",
        "        clips[int(i/1000-5*int(i/5000))] = AudioSegment.from_file(path)\\\n",
        "        [5000*int(time[2*t]/5000):time[2*t]] + AudioSegment.from_file(path)\\\n",
        "        [time[2*t+1]:i+time[2*t+1]-time[2*t]] + AudioSegment.from_file(path)\\\n",
        "        [time[2*t]:time[2*t+1]] + AudioSegment.from_file(path)\\\n",
        "        [i+time[2*t+1]-time[2*t]:5000*int(time[2*t]/5000)+5000]\n",
        "      elif i>time[2*t] and i>time[2*t+1]:\n",
        "        clips[int(i/1000-5*int(i/5000))] = AudioSegment.from_file(path)[5000*int(time[2*t]/5000):time[2*t]] + AudioSegment.from_file(path)[time[2*t+1]:i+time[2*t+1]-time[2*t]] + AudioSegment.from_file(path)[time[2*t]:time[2*t+1]] + AudioSegment.from_file(path)[i+time[2*t+1]-time[2*t]:5000*int(time[2*t]/5000)+5000]\n",
        "\n",
        "    for i in range(len(clips)):\n",
        "      clips[i].export(Path(augmented_audio_with_background_path, stem + '_' + str(t+1) + '_' + str(i+1)+ '.wav'), format='wav')\n",
        "    \n",
        "with open(Path(raw_clips_metadata_path), 'r') as file_object:\n",
        "  file_reader = csv.reader(file_object, delimiter=',')\n",
        "  for raw_audio_meta in file_reader:\n",
        "    y = [int(x) for x in raw_audio_meta[1:] if x]\n",
        "    augment_wi_background(\n",
        "        Path(raw_audio_clips_path, raw_audio_meta[0]),\n",
        "        PurePath(Path(raw_audio_clips_path, raw_audio_meta[0])).stem,\n",
        "        *y\n",
        "    )"
      ],
      "metadata": {
        "id": "pvvbrUOPxh04"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}