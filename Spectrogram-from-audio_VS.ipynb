{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Program to generate spectrograms from an acoustic waveform."
      ],
      "metadata": {
        "id": "ucgt5iz2uyTD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wS23mLK2CRm0"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path, PurePath\n",
        "\n",
        "import numpy\n",
        "\n",
        "from scipy import signal\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "try:\n",
        "  from pydub import AudioSegment\n",
        "  from pydub.utils import get_array_type\n",
        "except:\n",
        "  !pip3 install pydub\n",
        "\n",
        "try:\n",
        "  import csv\n",
        "except:\n",
        "  !pip3 install csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path for directory containing raw audio clips\n",
        "raw_audio_clips_path = 'https://drive.google.com/drive/folders/1BIRX0Yb1JVuvmby-JZwHIpbiAc6lCcQv?usp=share_link'\n",
        "\n",
        "# Path for directory containing spectrograms generated from raw audio clips\n",
        "raw_audio_spectrograms_path = 'https://drive.google.com/drive/folders/1FFrMgj5Zg6ZNtK6ff7dmy1aPd5IABXLJ?usp=share_link'"
      ],
      "metadata": {
        "id": "qHqVB0bIMz_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an AudioSegment instance from the audio file at the path specified.\n",
        "# The information in the audio file is then used to create a numpy array, which\n",
        "# is used as an argument in scipy.signal.spectrogram() to generate the\n",
        "# corresponding spectrogram.\n",
        "\n",
        "def generate_spectrogram_from_audio(path, stem):\n",
        "\n",
        "  instance_AS = AudioSegment.from_file(path)\n",
        "  samplerate = instance_AS.frame_rate\n",
        "  samples = numpy.array([])\n",
        "\n",
        "  bit_depth = instance_AS.sample_width*8\n",
        "  array_type = get_array_type(bit_depth)\n",
        "  data_instance_AS = numpy.fromstring(instance_AS._data, array_type)\n",
        "\n",
        "  channel_samples = []\n",
        "  for channel in numpy.arange(instance_AS.channels):\n",
        "    channel_samples.append(data_instance_AS[channel::instance_AS.channels])\n",
        "  samples = numpy.array(channel_samples, dtype=array_type)\n",
        "\n",
        "  frequencies, times, Sxx = signal.spectrogram(data_instance_AS, samplerate, scaling='spectrum')\n",
        "\n",
        "  plt.pcolormesh(times, frequencies, numpy.log10(Sxx[0]), cmap='jet')\n",
        "  plt.xticks(numpy.arange(0, 10, step=.2), rotation = (90))\n",
        "  plt.tick_params(axis='x', which='major', labelsize=7)\n",
        "  \n",
        "  plt.ylabel('Frequency [Hz]')\n",
        "  plt.xlabel('Time [sec]')\n",
        "  \n",
        "  plt.savefig(Path(raw_audio_spectrograms_path, stem +'.png'), format='png')\n",
        "\n",
        "for path in Path(raw_audio_clips_path).rglob('*.flac'):\n",
        "  generate_spectrogram_from_audio(path, PurePath(path).stem)\n",
        "for path in Path(raw_audio_clips_path).rglob('*.WAV'):\n",
        "  generate_spectrogram_from_audio(path, PurePath(path).stem)\n",
        "\n",
        "#Alternately, can use the following in place of the two for loops above.\n",
        "#for path in Path(raw_audio_clips_path).glob('*.[fW][lA][aV]*'):\n",
        "  #generate_spectrogram_from_audio(path, PurePath(path).stem)"
      ],
      "metadata": {
        "id": "W2pP1M1eInHH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}