{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13lV8prNkX_U"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "try:\n",
        "  from opensoundscape.torch.models.cnn import CNN\n",
        "  from opensoundscape.torch.models.utils import BaseModule\n",
        "  from opensoundscape.torch.architectures import cnn_architectures\n",
        "except:\n",
        "  !pip install opensoundscape==0.7.1\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path for cattle presence metadata\n",
        "cattle_pres_metadata_path = '/path/to/directory/containing/cattle_pres/metadata.csv'\n",
        "\n",
        "# Path for cattle absence metadata\n",
        "cattle_abs_metadata_path = '/path/to/directory/containing/cattle_abs/metadata.csv'\n",
        "\n",
        "# Path for directory containing cattle presence audio clips\n",
        "cattle_pres_clips = '/path/to/directory/containing/cattle_pres/clips'\n",
        "\n",
        "# Path for directory containing cattle absence clips\n",
        "cattle_pres_clips = '/path/to/directory/containing/cattle_abs/metadata'\n",
        "\n",
        "# Path for csv file to write validation results to\n",
        "validation_results_csv_path = '/path/to/validation/results.csv'"
      ],
      "metadata": {
        "id": "8yZvJYi0qrMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a dataframe for the data in both the csv files with one-hot encoding for presence and absence of cattle."
      ],
      "metadata": {
        "id": "im5VB_Q_x6Rn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframe from cattle_pres.csv\n",
        "cattle_pres_df = pd.read_csv('/path/to/directory/containing/cattle_pres/metadata.csv', usecols = ['filename'], nrows=None)\n",
        "# Replace all '/' w/ '_' so that the records under 'filename' are same as names of audio files\n",
        "cattle_pres_df['filename'] = cattle_pres_df['filename'].str.replace('/','_')\n",
        "# File names should carry complete path of the audio files so that they can be downloaded (and converted to spectrograms, etc.)\n",
        "cattle_pres_df.filename = ['/path/to/directory/containing/cattle_pres/clips/'+f for f in cattle_pres_df.filename]\n",
        "# Insert features, 'present' and 'absent', and fill them w/ 1 & 0 respectively\n",
        "cattle_pres_df.insert(1, 'present', 1)\n",
        "cattle_pres_df.insert(1, 'absent', 0)\n",
        "\n",
        "# Repeat the above procedure starting w/ cattle_abs.csv\n",
        "cattle_abs_df = pd.read_csv('/path/to/directory/containing/cattle_abs/metadata.csv', usecols = ['filename'], nrows=None)\n",
        "cattle_abs_df['filename'] = cattle_abs_df['filename'].str.replace('/','_')\n",
        "cattle_abs_df.filename = ['/path/to/directory/containing/cattle_abs/clips'+f for f in cattle_abs_df.filename]\n",
        "cattle_abs_df.insert(1, 'present', 0)\n",
        "cattle_abs_df.insert(1, 'absent', 1)\n",
        "\n",
        "# Concatenate the two dataframes\n",
        "cattle_onehot_df = pd.concat([cattle_pres_df, cattle_abs_df])\n",
        "# Convert filename feature to index. The dataframe so obtained is in 'one-hot form' just like in the tutorial.\n",
        "cattle_onehot_df = cattle_onehot_df.set_index('filename')"
      ],
      "metadata": {
        "id": "eGX5NSmYzm9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Alternatively, can create one-hot vector using OneHotEncoder from sklearn."
      ],
      "metadata": {
        "id": "_eqafbShzIv6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dataframes for cattle presence. Insert a feature 'cattle' in the dataframe and populate w/ 'present'\n",
        "cattle_pres_df = pd.read_csv('/path/to/directory/containing/cattle_pres/metadata.csv', usecols = ['filename'], nrows = None)\n",
        "cattle_pres_df['filename'] = cattle_pres_df['filename'].str.replace('/','_')\n",
        "cattle_pres_df.filename = ['/path/to/directory/containing/cattle_pres/clips/'+f for f in cattle_pres_df.filename]\n",
        "cattle_pres_df.insert(1, 'cattle', 'present')\n",
        "\n",
        "# Repeat for cattle absence\n",
        "cattle_abs_df = pd.read_csv('/path/to/directory/containing/cattle_abs/metadata.csv', usecols = ['filename'], nrows = None)\n",
        "cattle_abs_df['filename'] = cattle_abs_df['filename'].str.replace('/','_')\n",
        "cattle_abs_df.filename = ['/path/to/directory/containing/cattle_abs/clips'+f for f in cattle_abs_df.filename]\n",
        "cattle_abs_df.insert(1, 'cattle', 'absent')\n",
        "\n",
        "# Merge the two dataframes created above\n",
        "cattle_df = pd.concat([cattle_pres_df, cattle_abs_df], ignore_index=True)\n",
        "\n",
        "# One-hot encoding\n",
        "\n",
        "enc = OneHotEncoder()  # Instantiating OneHotEncoder\n",
        "\n",
        "# Use 'cattle' feature to create labels\n",
        "# Step 1: enc.fit_transform(cattle_df[['cattle']])\n",
        "# Step 2: enc.fit_transform(cattle_df[['cattle']]).toarray()\n",
        "# Step 3: pd.DataFrame(enc.fit_transform(cattle_df[['cattle']]).toarray())\n",
        "# Step 4:\n",
        "cattle_onehot_df = cattle_df.join(pd.DataFrame(enc.fit_transform(cattle_df[['cattle']]).toarray()))\n",
        "# Drop 'cattle' and rename the labels\n",
        "cattle_onehot_df.drop('cattle', inplace=True, axis=1)\n",
        "cattle_onehot_df.rename(columns={0:'absent', 1:'present'}, inplace=True)\n",
        "\n",
        "cattle_onehot_df = cattle_onehot_df.set_index('filename')\n"
      ],
      "metadata": {
        "id": "mnFDcErW5Hy5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create training and holdout sets."
      ],
      "metadata": {
        "id": "3I2k4zpwGFJK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into two sets - for training and validation - using train_test_split() method from sklearn\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_onehot_df, valid_onehot_df = train_test_split(cattle_onehot_df, test_size=.2, random_state=1)"
      ],
      "metadata": {
        "id": "_IIkhBHR3Sxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulTejw8JvGVE"
      },
      "source": [
        "The following code cell is only meant to create an empty csv file w/ specified coloumns, at specified path, and need not be executed more than once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-ZUFBQotms9"
      },
      "outputs": [],
      "source": [
        "# Creating a dataframe for trained model's results on validation set.\n",
        "validation_results_df = pd.DataFrame\\\n",
        "(columns=['# records_cattle pres (train+valid)', '# records_cattle abs (train+valid)',\\\n",
        "          'N_epochs', 'Batch size', 'Epoch_best model', 'F1 score_best model', 'Training time'])\n",
        "# Create csv file at the specified location using the above dataframe\n",
        "validation_results_df.to_csv('/path/to/validation/results.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Va2v3E2Ue6jP"
      },
      "source": [
        "Training the model w/ training set and writing validation results to the csv file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Ahc7TkkCu8"
      },
      "outputs": [],
      "source": [
        "# Use ResNet18 architecture and instantiate CNN class\n",
        "arch = cnn_architectures.resnet18(num_classes=2, use_pretrained=True,\\\n",
        "                                  freeze_feature_extractor=True, num_channels=3)\n",
        "                                  # using ImageNet weights and freezing the feature extractor\n",
        "b_classifier = CNN(architecture=arch, classes=train_onehot_df.columns, sample_duration=10.0, single_target=True)\n",
        "\n",
        "# create a dataframe from validation results csv\n",
        "validation_results_df = pd.read_csv('/path/to/validation/results.csv', index_col=0)\n",
        "\n",
        "epochs = 100\n",
        "batch_size = 512\n",
        "\n",
        "# to record training time\n",
        "start_time = datetime.now()\n",
        "\n",
        "# call train()\n",
        "b_classifier.train(\n",
        "    train_onehot_df,\n",
        "    valid_onehot_df,\n",
        "    save_path='./binary_train/',\n",
        "    epochs=epochs,\n",
        "    batch_size=batch_size,\n",
        "    save_interval=1,\n",
        "    num_workers=0)\n",
        "end_time = datetime.now()\n",
        "\n",
        "# append the results to dataframe and write the dataframe back to the csv file\n",
        "validation_results_df = \\\n",
        "validation_results_df.append\\\n",
        "({'# records_cattle pres (train+valid)': len(cattle_onehot_df[cattle_onehot_df['present']==1]),\\\n",
        "  '# records_cattle abs (train+valid)': len(cattle_onehot_df[cattle_onehot_df['absent']==1]),\\\n",
        "  'N_epochs': epochs, 'Batch size': batch_size, 'Epoch_best model': b_classifier.best_epoch,\\\n",
        "  'F1 score_best model': b_classifier.best_score, 'Training time': end_time - start_time},\\\n",
        " ignore_index=True)\n",
        "validation_results_df.to_csv('/path/to/validation/results.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loss curve"
      ],
      "metadata": {
        "id": "A4t4Y_RIQyr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(b_classifier.loss_hist.keys(),b_classifier.loss_hist.values())\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')"
      ],
      "metadata": {
        "id": "deXomWIaPQeX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TY8SMXKrR-de"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}